{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Reading the EDF file containing EEG Record\n",
    "\n",
    "p1 = pyedflib.EdfReader(r'''C:\\Users\\lenovo\\Desktop\\altera\\SVM\\CHB\\Patient1\\chb01_21.edf''')\n",
    "n = p1.signals_in_file\n",
    "signal_labels = p1.getSignalLabels()\n",
    "sigbufs = np.zeros((n, p1.getNSamples()[0]))\n",
    "for i in np.arange(n):\n",
    "    sigbufs[i, :] = p1.readSignal(i)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many feature vectors?\n",
      "10\n",
      "Start from which second?\n",
      "343\n",
      "Label of feature vector?\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.signal import butter, lfilter,freqz, firwin\n",
    "import numpy as np\n",
    "\n",
    "# Extracting feature from the EEG records read\n",
    "\n",
    "fs = 256 #Sampling Frequency\n",
    "fc = np.linspace(0.5,25,3) #Frequecy Range\n",
    "n = 1001 #Filter order\n",
    "x = input('How many feature vectors?\\n')\n",
    "s = input('Start from which second?\\n')\n",
    "ch = p1.signals_in_file #Number of channels\n",
    "label = input('Label of feature vector?\\n') #Label for seizure and non-seizure feature vector extracted\n",
    "Xt = np.empty((0,ch*8+1), int)\n",
    "s = int(s)\n",
    "\n",
    "# Creating the matrix used for training dataset\n",
    "\n",
    "for k in range(0,int(x)):\n",
    "    X2 = np.array([])\n",
    "    X1 = np.array([])\n",
    "    for channel in range(0,int(ch)):\n",
    "        sample = s*fs\n",
    "        y1 = sigbufs[channel]\n",
    "        y1 = y1[sample:sample+256]\n",
    "        X1 = np.array([np.mean(y1),np.median(y1),np.array(scipy.stats.mode(y1))[0],np.std(y1),np.amin(y1),np.amax(y1)])\n",
    "        for i in range(0,2):\n",
    "            a = firwin(n,[fc[i], fc[i+1]], window = 'nuttall',pass_zero = False,nyq = fs) #Used FIR Filter\n",
    "            y_filter = lfilter(a,1,y1)\n",
    "            e = sum(np.absolute(y_filter)**2)\n",
    "            X1 = np.append(X1,e)\n",
    "        X2 = np.append(X2,X1)\n",
    "    X2 = np.append(X2,int(label))\n",
    "    Xt = np.append(Xt,[X2],axis = 0)\n",
    "    s = s+1\n",
    "    \n",
    "    \n",
    "# Transferring the data to a test file\n",
    "# Will be copied to Original CSV dataset 'PythonData.CSV' when structing training data\n",
    "\n",
    "file = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\test.xlsx'    \n",
    "a = pd.DataFrame(Xt)\n",
    "a.to_excel(file,index=False, index_label=None,sheet_name='1', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Result:\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      "Bias: [-2.30191565]\n",
      "Number of Iteration: (233,)\n",
      "Values of alpha:\n",
      " [[ -1.17909355e+01  -2.24084081e+01  -1.60685727e+01  -4.15566889e+00\n",
      "   -4.49533817e+00  -6.87378791e-01  -1.07818657e+01  -4.71256822e+01\n",
      "   -3.00344395e+01  -4.31734381e+01  -4.12486170e+00  -2.16504200e+01\n",
      "   -3.65531555e+01  -1.08557648e+01  -7.68199404e+00  -5.33108893e+00\n",
      "   -1.08408522e+01  -4.97285515e+00  -4.19703483e+00  -1.74617768e+01\n",
      "   -2.89916117e+01  -1.28504403e+01  -4.40186594e+00  -1.52821924e+01\n",
      "   -1.08518522e+01  -2.48324628e+01  -1.57690840e+01  -8.69913365e-01\n",
      "   -9.92571405e+00  -2.08244259e+01  -1.18996545e+00  -1.08130957e+01\n",
      "   -1.15877685e+00  -1.80868465e+01  -6.88397086e+00  -9.57539707e+00\n",
      "   -4.26969563e+01  -1.89708954e+01  -1.51213503e+01  -4.08929276e+01\n",
      "   -1.94026849e+01  -5.57426919e-01  -1.14811401e+01  -1.54067183e+01\n",
      "   -1.50866501e+01  -7.64049014e+00  -8.91261652e+00  -2.00640694e+01\n",
      "   -2.09061947e+01  -1.92494703e+00  -1.72083276e+01  -4.06180963e+01\n",
      "   -1.50047864e+00  -3.28113812e+00  -1.51317976e+01  -1.31703757e+00\n",
      "   -3.40047353e+00  -3.59101100e-01  -1.67107761e+00  -5.27960209e+00\n",
      "   -2.94137026e+00  -1.87268295e+00  -1.45069271e+00  -6.42380409e-01\n",
      "   -9.47542186e+00  -3.28048707e-02  -7.47873283e+00  -1.45576522e+00\n",
      "   -1.17040129e+01  -2.17062675e+01  -3.75731543e+00  -4.07616997e+00\n",
      "   -3.84205958e+00  -1.20784507e+01  -3.86992932e+00  -2.38857107e+00\n",
      "   -5.67471597e-01  -1.03384468e+01  -1.38169636e+01  -1.54294614e+01\n",
      "   -8.30457360e+00  -6.20968776e+00  -1.22687692e+01  -1.38141950e+01\n",
      "   -2.27529347e+00  -2.22570496e+01  -4.35881406e-01  -2.45342779e+00\n",
      "   -4.13546801e+00  -3.19937996e+00  -3.70585042e+01  -5.34022428e+00\n",
      "   -1.61342867e+01  -3.20957789e+01  -7.95000444e+00  -2.44975589e-01\n",
      "   -2.15444047e+00  -7.54806097e-01  -1.39915753e-01  -4.08465796e+00\n",
      "   -2.32623544e+00  -2.84410591e+00  -2.45751340e+00  -5.62487732e+00\n",
      "   -7.46906285e-01  -1.32705804e+01  -4.35265931e+00  -3.92404148e+01\n",
      "   -9.01637726e-01  -6.39511755e-01  -4.47126285e+00  -9.91430012e+00\n",
      "   -4.81577379e-01  -2.95765249e+00  -2.76094291e+00  -6.72518337e-01\n",
      "   -1.10259733e+00  -2.80088266e+01  -1.75595277e+00  -1.06156790e+01\n",
      "   -6.65706990e+00  -2.21257038e+01  -5.87771543e+00  -1.06482430e+00\n",
      "   -1.00443304e+00  -3.42806377e+00  -2.39417454e+00  -7.29060920e-02\n",
      "   -3.77148402e+00  -3.83239388e+00  -7.74384098e+00  -4.35374573e-01\n",
      "   -2.94132073e-02  -1.91490233e+00  -2.02653998e+00  -1.95575889e+00\n",
      "   -8.37226833e+00  -2.17767685e+00  -8.28928282e+00  -5.79370582e-02\n",
      "   -8.99077291e+00  -1.28114016e+00  -7.41756592e+00  -3.41298986e+00\n",
      "   -4.04238965e+00  -4.58919380e+00   1.00000000e+02   6.26650107e+01\n",
      "    4.14011720e+00   4.35147581e+01   9.56750639e+01   8.05636555e+01\n",
      "    6.78993793e+00   7.09280718e+00   8.75581655e-02   4.43732317e+00\n",
      "    2.77626261e-01   2.35850397e+00   2.50138275e+00   1.35467953e+00\n",
      "    3.43638521e-01   9.85498074e-01   4.36412760e-01   1.23698873e+00\n",
      "    5.35996760e+00   2.90909896e-01   1.55076283e+00   1.00000000e+02\n",
      "    1.00000000e+02   5.55287462e+01   1.00000000e+02   1.00000000e+02\n",
      "    1.21988324e+00   2.30944028e+00   1.33673336e-01   2.85413749e-01\n",
      "    1.96670318e+01   1.18575428e+01   1.15743744e+00   6.71379968e+00\n",
      "    2.29173415e+00   3.42985992e+00   2.00131950e+00   1.23082401e+00\n",
      "    2.04434173e+01   1.60963967e+01   6.34881414e+00   1.82749341e-02\n",
      "    2.34958854e+00   3.26629085e+00   6.41014680e-01   1.09816851e-01\n",
      "    3.04496450e-01   1.36113065e+00   3.78065559e-01   5.28359843e-01\n",
      "    2.49063936e+00   3.51897426e+00   9.92222221e-01   2.35968773e+00\n",
      "    1.38433632e+01   7.95567199e+00   9.70730376e+00   1.00000000e+02\n",
      "    8.91305959e+00   5.56171373e+01   3.90105360e+01   3.86092128e+00\n",
      "    1.97594553e+00   2.48353296e+00   1.78614880e+00   2.75660872e+01\n",
      "    2.14623085e+01   1.20409701e+00   3.77720657e+00   9.51620530e+00\n",
      "    8.12348579e+00   2.93334050e-01   1.79050462e-01   4.57659068e-01\n",
      "    2.02713463e+01   2.42481344e+00   5.79607667e+00   1.91693312e+00\n",
      "    4.65617768e-01   6.46407425e+00   2.76311593e+00   1.12406345e+01\n",
      "    7.12792790e-01   4.66742624e-01   3.25926556e+00   2.21860389e+01\n",
      "    7.48219877e+00]]\n",
      "No of Support Vectors used for seizure: 87\n",
      "No of Support Vectors used for non seizure: 146\n",
      "Array of Support Vectors:\n",
      " [[-0.0530753   0.58308832 -1.45348868 ...,  0.03364786 -0.19160445\n",
      "  -0.38756789]\n",
      " [-0.35210577 -0.21112634  0.00771367 ...,  0.46833462 -0.16910506\n",
      "   0.19906608]\n",
      " [-0.02429347  0.59963446  0.5602081  ...,  0.01692914  0.1023195\n",
      "   0.00413913]\n",
      " ..., \n",
      " [ 1.10010502  1.39384912  0.08041031 ...,  1.09807313  0.30045506\n",
      "   0.00721456]\n",
      " [-2.14230074 -2.08084003 -2.83472474 ...,  1.24854162  1.3873598\n",
      "  -0.13543806]\n",
      " [-0.67546786  2.35352517  1.64338795 ...,  0.95875045 -0.18380526\n",
      "  -0.31891443]]\n",
      "Labels of the Support Vectors:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Designing the SVM classifier and detecting seizure\n",
    "\n",
    "filename = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Study\\\\Master Thesis\\\\CHB\\\\Patient1\\\\PythonData.csv'     # Support Vectors\n",
    "data = pd.read_csv(filename, header  = None)\n",
    "X = data.iloc[:,0:ch*8].values\n",
    "y = data.iloc[:,ch*8].values\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)  #Scaling the Training Dataset\n",
    "filename2 = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\test.xlsx'    # Test Vectors\n",
    "data2 = pd.read_excel(filename2, header =None)\n",
    "X2 = data2.iloc[:,0:ch*8].values\n",
    "X2 = scaler.transform(X2)  #Scaling the Test Datasets\n",
    "\n",
    "# Designing the classifier by defining kernel parameters and fitting with Training Dataset\n",
    "clf = svm.SVC(kernel = 'rbf', gamma = .001,C = 100).fit(X,y)\n",
    "\n",
    "#Printing the prediction data\n",
    "print('Detection Result:\\n',clf.predict(X2))\n",
    "\n",
    "#Writing the prediction result in excel file to verify false alarm      \n",
    "file = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\FA.xlsx'    \n",
    "b = pd.DataFrame(clf.predict(X2))\n",
    "b.to_excel(file,index=False, index_label=None,sheet_name='1', header = None)\n",
    "\n",
    "\n",
    "#Finding the parameters of SVM classifier\n",
    "print('Bias:',clf.intercept_)                #Value of bias(b)\n",
    "iteration = clf.dual_coef_.shape[1:2]\n",
    "print('Number of Iteration:',iteration)      #Value of i\n",
    "print('Values of alpha:\\n',clf.dual_coef_)   #Value of alpha\n",
    "\n",
    "#Checking stats on support vectors\n",
    "s = clf.n_support_\n",
    "print('No of Support Vectors used for seizure:',s[1])\n",
    "print('No of Support Vectors used for non seizure:',s[0])\n",
    "print('Array of Support Vectors:\\n',clf.support_vectors_)           #The value of x\n",
    "print('Labels of the Support Vectors:\\n',y[(clf.support_)])         #The vaue of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Grid Search method to select kernel and parameters\n",
    "\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "filename = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\CHB\\\\Patient1\\\\PythonData.csv'\n",
    "data = pd.read_csv(filename, header = None)\n",
    "X = data.iloc[:,0:ch*8].values\n",
    "y = data.iloc[:,ch*8].values\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1, .05, 1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 50, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(),tuned_parameters,cv = 5, scoring = 'accuracy').fit(X,y)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)\n",
    "z = pd.DataFrame(clf.grid_scores_)[['parameters','mean_validation_score']]\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saving the training and testing dataset in excel file\n",
    "\n",
    "file = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Study\\\\Master Thesis\\\\CHB\\\\Python\\\\MasterSV1.xlsx' \n",
    "file2 = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Study\\\\Master Thesis\\\\CHB\\\\Python\\\\MasterAlpha1.xlsx'   \n",
    "file3 = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\Study\\\\Master Thesis\\\\CHB\\\\Python\\\\MasterTest1.xlsx'\n",
    "a = pd.DataFrame(clf.support_vectors_)\n",
    "a.to_excel(file,index=False, index_label=None,sheet_name='sv', header = None)\n",
    "b = pd.DataFrame(clf.dual_coef_)\n",
    "b.to_excel(file2,index=False, index_label=None,sheet_name='alpha', header = None)\n",
    "c = pd.DataFrame(X2)\n",
    "c.to_excel(file3,index=False, index_label=None,sheet_name='z', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
